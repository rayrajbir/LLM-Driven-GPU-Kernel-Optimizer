# ğŸ§  LLVM-CUDA-NLP: LLM-Driven GPU Kernel Optimizer

A research-grade prototype that uses NLP (via LLMs) to generate and optimize CUDA GPU kernels, compiled with LLVM for performance analysis. This project bridges high-level natural language requests with low-level GPU code using a combination of transformers, CUDA, and LLVM IR passes.

---

## ğŸš€ Project Goals

* ğŸ—£ï¸ Accept natural language input like:

  > "Optimize this kernel for matrix multiplication with shared memory and warp-level primitives"

* ğŸ¤– Use an LLM (like FLAN-T5 or OpenAI) to:

  * Interpret the optimization request
  * Suggest kernel transformations or parameters
  * Optionally generate new CUDA code

* âš™ï¸ Compile the CUDA kernel using `nvcc` and analyze with LLVM passes.

* ğŸ“Š Provide hooks for performance tuning and benchmarking.

---

## ğŸ§ª Requirements

### Python

* `transformers`
* `torch`
* `openai` *(optional)*

Install with:

```bash
pip install -r requirements.txt
```

---

### System

* **CUDA Toolkit** (with `nvcc`)
* **LLVM** (v10+)
* **CMake** (v3.10+)

---

## ğŸ“ Project Structure

```
LLVM-CUDA-NLP/
â”œâ”€â”€ models/                  # LLM interfaces and prompt templates
â”œâ”€â”€ kernels/                 # CUDA kernel sources
â”œâ”€â”€ llvm_passes/            # LLVM IR manipulation and analysis passes
â”œâ”€â”€ benchmarks/             # Performance tests and metrics
â”œâ”€â”€ utils/                  # Utilities for I/O, compilation, logging
â”œâ”€â”€ main.py                 # Main CLI entry point
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

---

## âš™ï¸ Usage Example

```bash
python main.py \
  --prompt "Optimize for 2D convolution with shared memory and minimal bank conflicts" \
  --input-kernel kernels/conv.cu \
  --output-kernel kernels/conv_optimized.cu
```

You can also use the OpenAI API for enhanced interpretation:

```bash
python main.py --use-openai --api-key <your-key> [...]
```

---

## ğŸ” Features

* LLM-powered prompt interpretation
* Auto-suggestion of CUDA best practices (e.g., loop unrolling, memory coalescing)
* LLVM IR analysis hooks (e.g., register pressure, instruction counts)
* Integration with performance profilers like Nsight
* Extensible for reinforcement learning-based tuning (future)

---

## ğŸ“ˆ Benchmarking

Benchmark utilities provided in `benchmarks/`:

```bash
python benchmarks/benchmark_runner.py --kernel kernels/conv_optimized.cu
```

Results include:

* Execution time
* Occupancy
* Warp efficiency
* Shared memory utilization

---

## ğŸ¤ Contributing

We welcome PRs and ideas! To contribute:

1. Fork the repository
2. Create a new branch
3. Submit a pull request with a clear description

---

## ğŸ“œ License

This project is licensed under the MIT License. See `LICENSE` for details.

---

## ğŸ™Œ Acknowledgments

* OpenAI for GPT APIs
* Hugging Face Transformers
* NVIDIA CUDA Toolkit
* LLVM community
